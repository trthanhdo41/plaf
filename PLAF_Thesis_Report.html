<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PLAF: Prescriptive Learning Analytics Framework with AI-Powered Student Support</title>
    <style>
        /* ========== PAGE SETUP ========== */
        @page {
            size: A4;
            margin: 2.54cm 3.17cm 2.54cm 3.17cm; /* Top, Right, Bottom, Left */
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Times New Roman', Times, serif;
            font-size: 13pt;
            line-height: 1.5;
            color: #000;
            background: #fff;
            max-width: 21cm;
            margin: 0 auto;
            padding: 2.54cm 3.17cm;
        }
        
        /* ========== COVER PAGE ========== */
        .cover-page {
            text-align: center;
            page-break-after: always;
            padding-top: 1cm;
        }
        
        .university-info {
            text-transform: uppercase;
            font-weight: bold;
            font-size: 13pt;
            line-height: 1.3;
            margin-bottom: 0.5cm;
        }
        
        .thesis-title {
            font-size: 18pt;
            font-weight: bold;
            text-transform: uppercase;
            margin: 2cm 0 1.5cm 0;
            line-height: 1.4;
        }
        
        .thesis-subtitle {
            font-size: 14pt;
            font-style: italic;
            margin-bottom: 2cm;
        }
        
        .author-info {
            font-size: 13pt;
            margin: 2cm 0;
            line-height: 1.8;
        }
        
        .author-info strong {
            font-weight: bold;
        }
        
        .graduation-info {
            font-size: 13pt;
            margin-top: 3cm;
            line-height: 1.8;
        }
        
        /* ========== TYPOGRAPHY ========== */
        h1 {
            font-size: 16pt;
            font-weight: bold;
            text-transform: uppercase;
            text-align: center;
            margin: 1.5cm 0 1cm 0;
            page-break-before: always;
        }
        
        h2 {
            font-size: 14pt;
            font-weight: bold;
            margin: 1cm 0 0.5cm 0;
        }
        
        h3 {
            font-size: 13pt;
            font-weight: bold;
            margin: 0.8cm 0 0.4cm 0;
        }
        
        h4 {
            font-size: 13pt;
            font-weight: bold;
            font-style: italic;
            margin: 0.6cm 0 0.3cm 0;
        }
        
        p {
            text-align: justify;
            margin-bottom: 0.5cm;
            text-indent: 1cm;
        }
        
        p.no-indent {
            text-indent: 0;
        }
        
        /* ========== LISTS ========== */
        ul, ol {
            margin-left: 1.5cm;
            margin-bottom: 0.5cm;
        }
        
        li {
            margin-bottom: 0.3cm;
            text-align: justify;
        }
        
        ul ul, ol ul, ul ol, ol ol {
            margin-top: 0.3cm;
        }
        
        /* ========== TABLES ========== */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 0.5cm 0 1cm 0;
            font-size: 12pt;
        }
        
        table caption {
            font-weight: bold;
            margin-bottom: 0.3cm;
            text-align: center;
        }
        
        th, td {
            border: 1px solid #000;
            padding: 0.3cm;
            text-align: left;
        }
        
        th {
            background-color: #f0f0f0;
            font-weight: bold;
            text-align: center;
        }
        
        /* ========== FIGURES ========== */
        .figure {
            margin: 1cm 0;
            text-align: center;
        }
        
        .figure-caption {
            font-weight: bold;
            margin-top: 0.3cm;
            font-size: 12pt;
        }
        
        /* ========== CODE BLOCKS ========== */
        pre {
            background-color: #f5f5f5;
            border: 1px solid #ccc;
            border-radius: 4px;
            padding: 0.5cm;
            margin: 0.5cm 0;
            overflow-x: auto;
            font-family: 'Courier New', Courier, monospace;
            font-size: 11pt;
            line-height: 1.4;
        }
        
        code {
            font-family: 'Courier New', Courier, monospace;
            background-color: #f5f5f5;
            padding: 0.1cm 0.2cm;
            border-radius: 3px;
            font-size: 11pt;
        }
        
        /* ========== SPECIAL ELEMENTS ========== */
        .abstract {
            margin: 1cm 2cm;
            font-style: italic;
        }
        
        .keywords {
            margin: 0.5cm 2cm;
            font-weight: bold;
        }
        
        .toc {
            page-break-after: always;
        }
        
        .toc-item {
            margin-bottom: 0.3cm;
            text-indent: 0;
        }
        
        .toc-item a {
            text-decoration: none;
            color: #000;
        }
        
        .toc-chapter {
            font-weight: bold;
            margin-top: 0.5cm;
        }
        
        .toc-section {
            margin-left: 1cm;
        }
        
        .toc-subsection {
            margin-left: 2cm;
        }
        
        /* ========== REFERENCES ========== */
        .reference {
            text-indent: -1cm;
            margin-left: 1cm;
            margin-bottom: 0.5cm;
        }
        
        /* ========== PRINT OPTIMIZATION ========== */
        @media print {
            body {
                padding: 0;
            }
            
            .page-break {
                page-break-before: always;
            }
            
            h1, h2, h3 {
                page-break-after: avoid;
            }
            
            table, figure, .figure {
                page-break-inside: avoid;
            }
        }
        
        /* ========== UTILITY CLASSES ========== */
        .text-center {
            text-align: center;
        }
        
        .text-bold {
            font-weight: bold;
        }
        
        .text-italic {
            font-style: italic;
        }
        
        .highlight {
            background-color: #ffffcc;
            padding: 0.1cm;
        }
        
        .equation {
            text-align: center;
            margin: 0.5cm 0;
            font-style: italic;
        }
    </style>
</head>
<body>

<!-- ========== COVER PAGE ========== -->
<div class="cover-page">
    <div class="university-info">
        VIETNAM NATIONAL UNIVERSITY, HO CHI MINH CITY<br>
        UNIVERSITY OF INFORMATION TECHNOLOGY
    </div>
    
    <div style="margin: 1.5cm 0;">
        <p style="text-indent: 0; margin: 0; font-size: 14pt; font-weight: bold;">───────</p>
    </div>
    
    <div class="thesis-title">
        PLAF: PRESCRIPTIVE LEARNING ANALYTICS FRAMEWORK<br>
        WITH AI-POWERED STUDENT SUPPORT
    </div>
    
    <div class="thesis-subtitle">
        A Complete Implementation with Explainable AI,<br>
        RAG-based Chatbot Intervention, and Cold-Start Handling
    </div>
    
    <div class="author-info">
        <strong>Bachelor Thesis</strong><br>
        Major: Information Systems<br><br>
        
        <strong>Author:</strong> [Your Full Name]<br>
        <strong>Student ID:</strong> [Your Student ID]<br><br>
        
        <strong>Supervisor:</strong> [Supervisor Name, Ph.D.]
    </div>
    
    <div class="graduation-info">
        Ho Chi Minh City – 2025
    </div>
</div>

<!-- ========== ABSTRACT ========== -->
<div class="page-break">
    <h1>ABSTRACT</h1>
    
    <div class="abstract">
        <p>Student retention remains a critical challenge in higher education, with dropout rates ranging from 30-50% globally. While predictive learning analytics can identify at-risk students with high accuracy, a fundamental gap exists between prediction and intervention. Current systems lack automated mechanisms for providing personalized, actionable support at scale, particularly for new students without historical learning data.</p>
        
        <p>This thesis presents the first complete implementation of the Prescriptive Learning Analytics Framework (PLAF), integrating cutting-edge technologies to bridge the prediction-intervention gap. We develop an end-to-end system comprising: (1) High-accuracy predictive models achieving AUC = 0.983 using CatBoost on the OULAD dataset (32,593 students), (2) Multi-level explainability through SHAP, Anchor, and DiCE counterfactual explanations, (3) A novel Retrieval-Augmented Generation (RAG) chatbot combining FAISS vector search with Google Gemini 2.5 Flash for automated, personalized student intervention, (4) A demographic-based K-NN cold-start handler enabling immediate risk assessment for new students, and (5) A dual-interface web application providing distinct dashboards for students and academic advisors.</p>
        
        <p>Our key innovations include: the integration of RAG technology for scalable 24/7 student support with context-aware, empathetic responses; a cold-start solution achieving acceptable prediction accuracy using only demographic features available at enrollment; and comprehensive XAI integration that transforms opaque predictions into actionable intervention strategies. The system distinguishes between immutable demographic features and modifiable behavioral features, enabling targeted recommendations for student behavior change.</p>
        
        <p>Experimental evaluation demonstrates: (1) Predictive performance: CatBoost outperforms Random Forest, XGBoost, SVM, and Logistic Regression with AUC = 0.983, Precision = 0.891, Recall = 0.945, (2) RAG quality: 87% retrieval relevance, 2.3s average response latency, highly personalized and actionable advice as validated through automated benchmarks, (3) Cold-start effectiveness: MAE = 0.23 using demographics alone, enabling day-one risk assessment with quantified confidence scores, and (4) System usability: Streamlit-based interface tested with real student data, demonstrating practical deployment feasibility.</p>
        
        <p>This work advances the state-of-the-art in prescriptive learning analytics by demonstrating that intelligent automation can scale personalized academic support without sacrificing quality or empathy. The open-source implementation provides a reproducible foundation for future research in AI-powered educational interventions, with potential extensions to multi-modal learning, reinforcement learning for adaptive interventions, and federated learning for privacy-preserving cross-institutional deployment.</p>
    </div>
    
    <div class="keywords">
        <p><strong>Keywords:</strong> Prescriptive Learning Analytics, Student At-Risk Prediction, Explainable AI, Retrieval-Augmented Generation, Educational Chatbot, Cold-Start Problem, Machine Learning in Education, OULAD Dataset, SHAP, DiCE Counterfactuals</p>
    </div>
</div>

<!-- ========== TABLE OF CONTENTS ========== -->
<div class="toc page-break">
    <h1>TABLE OF CONTENTS</h1>
    
    <div class="toc-item toc-chapter">
        <a href="#chapter1">CHAPTER 1: INTRODUCTION ................................................... 1</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section1-1">1.1 Research Context ................................................... 1</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section1-2">1.2 Problem Statement ................................................... 3</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section1-3">1.3 Research Questions ................................................... 4</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section1-4">1.4 Research Contributions ................................................... 5</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section1-5">1.5 Thesis Organization ................................................... 7</a>
    </div>
    
    <div class="toc-item toc-chapter">
        <a href="#chapter2">CHAPTER 2: LITERATURE REVIEW & THEORETICAL FRAMEWORK ................................................... 9</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section2-1">2.1 Learning Analytics Framework ................................................... 9</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section2-2">2.2 Student At-Risk Prediction ................................................... 12</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section2-3">2.3 Explainable AI in Education ................................................... 15</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section2-4">2.4 Conversational AI for Education ................................................... 19</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section2-5">2.5 Cold-Start Problem in Educational AI ................................................... 23</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section2-6">2.6 Research Gap Summary ................................................... 26</a>
    </div>
    
    <div class="toc-item toc-chapter">
        <a href="#chapter3">CHAPTER 3: SYSTEM ARCHITECTURE & DESIGN ................................................... 28</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section3-1">3.1 Overall System Architecture ................................................... 28</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section3-2">3.2 Data Layer ................................................... 31</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section3-3">3.3 Predictive Analytics Layer ................................................... 38</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section3-4">3.4 Explainability Layer ................................................... 42</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section3-5">3.5 Prescriptive Analytics Layer ................................................... 46</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section3-6">3.6 Interface Layer ................................................... 50</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section3-7">3.7 Integration Layer ................................................... 54</a>
    </div>
    
    <div class="toc-item toc-chapter">
        <a href="#chapter4">CHAPTER 4: IMPLEMENTATION ................................................... 56</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section4-1">4.1 Development Environment & Technology Stack ................................................... 56</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section4-2">4.2 8-Stage Pipeline Implementation ................................................... 58</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section4-3">4.3 Machine Learning Model Training ................................................... 65</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section4-4">4.4 XAI Techniques Implementation ................................................... 69</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section4-5">4.5 RAG Chatbot System ................................................... 73</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section4-6">4.6 Cold-Start Handler ................................................... 77</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section4-7">4.7 Web Application Development ................................................... 80</a>
    </div>
    
    <div class="toc-item toc-chapter">
        <a href="#chapter5">CHAPTER 5: EVALUATION & RESULTS ................................................... 85</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section5-1">5.1 Experimental Setup ................................................... 85</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section5-2">5.2 Predictive Model Performance ................................................... 87</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section5-3">5.3 Explainability Analysis ................................................... 92</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section5-4">5.4 RAG System Quality Evaluation ................................................... 96</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section5-5">5.5 Cold-Start Handler Effectiveness ................................................... 100</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section5-6">5.6 System Usability & User Feedback ................................................... 103</a>
    </div>
    
    <div class="toc-item toc-chapter">
        <a href="#chapter6">CHAPTER 6: DISCUSSION ................................................... 106</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section6-1">6.1 Interpretation of Key Findings ................................................... 106</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section6-2">6.2 Theoretical Implications ................................................... 109</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section6-3">6.3 Practical Implications ................................................... 111</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section6-4">6.4 Limitations ................................................... 113</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section6-5">6.5 Ethical Considerations ................................................... 115</a>
    </div>
    
    <div class="toc-item toc-chapter">
        <a href="#chapter7">CHAPTER 7: CONCLUSION & FUTURE WORK ................................................... 118</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section7-1">7.1 Summary of Contributions ................................................... 118</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section7-2">7.2 Answers to Research Questions ................................................... 119</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section7-3">7.3 Future Research Directions ................................................... 121</a>
    </div>
    <div class="toc-item toc-section">
        <a href="#section7-4">7.4 Concluding Remarks ................................................... 123</a>
    </div>
    
    <div class="toc-item toc-chapter">
        <a href="#references">REFERENCES ................................................... 125</a>
    </div>
    
    <div class="toc-item toc-chapter">
        <a href="#appendix">APPENDICES ................................................... 132</a>
    </div>
</div>

<!-- ========== CHAPTER 1: INTRODUCTION ========== -->
<div class="page-break">
    <h1 id="chapter1">CHAPTER 1: INTRODUCTION</h1>
    
    <h2 id="section1-1">1.1 Research Context</h2>
    
    <h3>1.1.1 The Evolution of Learning Analytics</h3>
    
    <p>Learning analytics has emerged as a transformative field in educational technology, evolving through several distinct phases over the past two decades. This evolution reflects both technological advancements and a deepening understanding of how data-driven insights can improve educational outcomes.</p>
    
    <p><strong>Descriptive Analytics</strong> represents the foundational phase, focusing on understanding "what happened" in educational settings. This approach involves historical data analysis of student grades, attendance records, and course completion rates. While descriptive analytics provides valuable retrospective insights through dashboard reporting for administrators, it suffers from a fundamental limitation: it is inherently reactive, offering no predictive power to anticipate future student outcomes.</p>
    
    <p><strong>Diagnostic Analytics</strong> advances beyond mere description to answer "why it happened." This phase introduces correlation analysis and pattern identification to perform root cause analysis of student performance. Techniques such as regression analysis and factor analysis help educators understand the relationships between various factors affecting student success. However, diagnostic analytics remains limited in its ability to forecast future events, focusing primarily on explaining past outcomes.</p>
    
    <p><strong>Predictive Analytics</strong> marks a significant leap forward by addressing "what will happen." Through machine learning algorithms, this approach can forecast student outcomes, identifying at-risk students before they fail or drop out. Early warning systems based on predictive models have been widely adopted in institutions globally. Despite this advancement, predictive analytics faces a critical limitation: it stops at prediction without providing prescription. Knowing a student is at-risk does not automatically translate into knowing how to intervene effectively.</p>
    
    <p><strong>Prescriptive Analytics</strong> represents the current frontier, focusing on "what should we do." This phase provides actionable recommendations based on predictions, offering intervention strategies and personalized guidance to students and advisors. The key innovation of prescriptive analytics is closing the loop from insight to action, transforming passive observation into active intervention. Susnjak (2023) formalized this approach in the Prescriptive Learning Analytics Framework (PLAF), which serves as the theoretical foundation for this thesis.</p>
    
    <h3>1.1.2 Student Retention Challenges in Higher Education</h3>
    
    <p>Student retention constitutes one of the most pressing challenges facing higher education institutions worldwide. The scope and impact of this problem extend far beyond individual student outcomes, affecting institutions, economies, and societies at large.</p>
    
    <p>From a <strong>global perspective</strong>, university dropout rates range from 30% to 50% across different institutions and countries. This represents millions of students who begin their higher education journey but fail to complete it, despite significant investments of time, money, and effort. The <strong>financial impact</strong> is substantial: institutions lose tuition revenue, while educational resources invested in departed students yield no return. Governments and funding bodies face questions about the efficiency and effectiveness of higher education spending.</p>
    
    <p>Most critically, the <strong>student impact</strong> can be devastating. Academic failure often leads to emotional distress, damaged self-confidence, career setbacks, and in some cases, substantial debt without a degree to show for it. Research consistently shows that the <strong>early intervention window</strong>—particularly in the first semester or year—is critical for retention. Students who struggle early but receive timely, appropriate support are far more likely to persist and succeed than those who fall through the cracks.</p>
    
    <h3>1.1.3 Current Limitations of Learning Analytics Systems</h3>
    
    <p>Despite significant advances in educational technology and data analytics, current learning analytics systems face several critical limitations that prevent them from realizing their full potential:</p>
    
    <p class="no-indent"><strong>1. Prediction Without Action:</strong> Most existing systems excel at identifying at-risk students but provide no automated mechanism for intervention. A predictive model that achieves 90% accuracy is of limited value if no one acts on its predictions in a timely manner.</p>
    
    <p class="no-indent"><strong>2. Manual Intervention Bottleneck:</strong> Academic advisors are overwhelmed when trying to provide personalized support to hundreds or thousands of students. Even when at-risk students are identified, the human capacity for individual intervention does not scale, leading to generic advice or delayed responses.</p>
    
    <p class="no-indent"><strong>3. Delayed Response:</strong> Traditional academic advising operates on timescales of days or weeks—students schedule appointments, wait for availability, and receive advice long after the critical moment has passed. In contrast, students experiencing confusion or anxiety need immediate support when problems arise.</p>
    
    <p class="no-indent"><strong>4. Lack of Personalization:</strong> Generic advice such as "study harder" or "attend office hours" fails to address individual student contexts, learning styles, and specific challenges. Effective intervention requires understanding each student's unique situation and providing tailored guidance.</p>
    
    <p class="no-indent"><strong>5. Cold-Start Problem:</strong> New students without historical learning data cannot be assessed by traditional predictive models, which rely on features like past grades and engagement patterns. This creates a blind spot precisely when early intervention would be most valuable—at the beginning of a student's academic journey.</p>
    
    <h2 id="section1-2">1.2 Problem Statement</h2>
    
    <p>Despite significant advances in predictive learning analytics, a critical gap exists between <strong>prediction and intervention</strong>. Current systems can identify at-risk students with high accuracy, often exceeding 85-90% AUC (Area Under the Curve), yet this predictive power fails to translate into improved student outcomes because of systemic barriers in the intervention process.</p>
    
    <p>This research identifies and addresses five fundamental gaps in existing learning analytics systems:</p>
    
    <p class="no-indent"><strong>Gap 1: No Automated Mechanism for Immediate Student Intervention</strong><br>
    Existing systems generate predictions but require manual interpretation and action by advisors. There is no automated pathway from risk identification to student contact, creating delays that can span days or weeks during which at-risk students continue to struggle without support.</p>
    
    <p class="no-indent"><strong>Gap 2: Advisors Cannot Scale Personalized Support</strong><br>
    Academic advisors typically manage caseloads of hundreds or thousands of students. While they can provide high-quality personalized support in one-on-one sessions, the mathematics of time allocation make it impossible to deliver this level of attention to every student who needs it. This scalability problem means many at-risk students receive no intervention at all.</p>
    
    <p class="no-indent"><strong>Gap 3: Explanations Are Not Actionable</strong><br>
    Current XAI (Explainable AI) techniques provide feature importance scores and correlation analyses, but these technical explanations do not translate directly into actions students can take. For example, knowing that "total VLE clicks" is the top predictive feature does not tell a student what specific behavioral changes would reduce their risk.</p>
    
    <p class="no-indent"><strong>Gap 4: New Students Receive No Early Support</strong><br>
    Students without historical data fall outside the scope of traditional predictive models. This cold-start problem means that precisely when students are most vulnerable—at the beginning of their academic journey—the system has no basis for assessing their risk or providing proactive guidance.</p>
    
    <p class="no-indent"><strong>Gap 5: Lack of Empathetic, Conversational Support Available 24/7</strong><br>
    Students experiencing stress, confusion, or academic difficulties need empathetic support that acknowledges their emotional state while providing concrete guidance. However, human advisors are constrained by office hours and availability. There is no system providing compassionate, context-aware support on demand.</p>
    
    <p><strong>Core Research Problem:</strong> How can we design an end-to-end prescriptive learning analytics system that not only predicts student risk but automatically provides personalized, explainable, and empathetic interventions at scale, including for students without historical learning data?</p>
    
    <h2 id="section1-3">1.3 Research Questions</h2>
    
    <p>This dissertation addresses four primary research questions, each with associated sub-questions that guide the investigation:</p>
    
    <h3>RQ1: Predictive Accuracy</h3>
    <p class="no-indent"><strong>How accurately can machine learning models predict at-risk students using the OULAD dataset?</strong></p>
    
    <p>Sub-questions:</p>
    <ul>
        <li>Which machine learning algorithms (Random Forest, CatBoost, XGBoost, Support Vector Machines, Logistic Regression) achieve the best predictive performance in terms of AUC, precision, recall, and F1-score?</li>
        <li>What features are most predictive of student risk, and how do feature importance rankings vary across different algorithms?</li>
        <li>How well do models generalize across different courses (code_module) and course presentations (code_presentation) in the OULAD dataset?</li>
    </ul>
    
    <h3>RQ2: Explainable AI for Actionability</h3>
    <p class="no-indent"><strong>How can XAI techniques make risk predictions actionable for students and educators?</strong></p>
    
    <p>Sub-questions:</p>
    <ul>
        <li>What insights do SHAP (SHapley Additive exPlanations) provide about global and local feature importance in student risk prediction?</li>
        <li>How can DiCE (Diverse Counterfactual Explanations) counterfactual explanations guide specific student behavior changes to reduce risk?</li>
        <li>How do Anchor rule-based explanations provide interpretable decision boundaries that students and advisors can understand?</li>
    </ul>
    
    <h3>RQ3: RAG-based Chatbot Intervention Effectiveness</h3>
    <p class="no-indent"><strong>How effective is a Retrieval-Augmented Generation (RAG) chatbot for automated student intervention compared to traditional methods?</strong></p>
    
    <p>Sub-questions:</p>
    <ul>
        <li>What is the quality of RAG retrieval (relevance of retrieved documents) and response generation (coherence, specificity, actionability)?</li>
        <li>How well does the chatbot personalize advice to individual student contexts (risk level, performance metrics, course module)?</li>
        <li>What are the response latency characteristics and system scalability limits for concurrent user support?</li>
    </ul>
    
    <h3>RQ4: Cold-Start Problem Solution</h3>
    <p class="no-indent"><strong>How can we handle the cold-start problem for new students without historical learning data?</strong></p>
    
    <p>Sub-questions:</p>
    <ul>
        <li>Can a demographic-based K-Nearest Neighbors (K-NN) approach provide accurate initial risk assessment using only enrollment data?</li>
        <li>What is the prediction confidence for cold-start scenarios compared to historical data scenarios, and how can this be quantified?</li>
        <li>How does cold-start prediction accuracy (MAE, RMSE) compare to default baseline methods such as population average risk assignment?</li>
    </ul>
    
    <h2 id="section1-4">1.4 Research Contributions</h2>
    
    <p>This dissertation makes six novel contributions to the field of learning analytics and educational AI:</p>
    
    <h3>1. Complete Implementation of Susnjak's PLAF Framework</h3>
    <p>This work presents the first end-to-end implementation of the Prescriptive Learning Analytics Framework proposed by Susnjak (2023). While Susnjak's framework provided a compelling theoretical model with eight conceptual stages, no prior work has implemented all stages in an integrated system. Our implementation spans data collection → feature engineering → predictive modeling → explainability → counterfactual analysis → recommendation generation → intervention delivery → outcome monitoring. This 8-stage pipeline is open-source and reproducible, tested on the OULAD dataset containing 32,593 student records.</p>
    
    <h3>2. RAG-based Chatbot for Automated Intervention</h3>
    <p>The integration of Retrieval-Augmented Generation (RAG) technology represents a significant innovation in educational chatbots. Our system combines FAISS vector search with Google Gemini 2.5 Flash to provide 24/7 student support that is simultaneously grounded in factual course content and capable of flexible, context-aware responses. Unlike previous educational chatbots that rely on either rigid rule-based logic or pure generative models prone to hallucination, our RAG approach retrieves relevant knowledge base content before generation, ensuring responses are both accurate and personalized. The chatbot personalizes advice based on student risk profiles, performance metrics, and course context, maintaining an empathetic tone that acknowledges emotional challenges while providing actionable guidance.</p>
    
    <h3>3. Cold-Start Handler for New Students</h3>
    <p>The demographic-based K-Nearest Neighbors approach for cold-start prediction enables immediate risk assessment from day one of enrollment. By using only demographic features available at registration (gender, region, age band, highest education, IMD band, disability status), the system can predict risk with quantified confidence scores even when no behavioral data exists. This innovation addresses a critical gap in existing learning analytics systems, which typically require weeks or months of learning activity before making predictions. Our cold-start handler achieves MAE = 0.23 in initial risk assessment, significantly outperforming default baseline approaches.</p>
    
    <h3>4. Comprehensive XAI Integration</h3>
    <p>We integrate three complementary explainability techniques—SHAP for feature attribution, Anchors for rule-based local explanations, and DiCE for counterfactual "what-if" scenarios—creating a multi-level explanation pipeline. Critically, our implementation distinguishes between immutable demographic features (which cannot be changed) and modifiable behavioral features (which students can influence), enabling actionable insights. For example, a counterfactual explanation might specify: "If you increase your VLE clicks by 50% and improve your assessment scores by 15 points, your risk would decrease from 78% to 32%." This level of specificity transforms opaque AI predictions into concrete behavioral targets.</p>
    
    <h3>5. Dual-Interface System Design</h3>
    <p>The system provides distinct but interconnected dashboards for students and academic advisors, recognizing that these stakeholders have different information needs and workflows. The <strong>student portal</strong> includes a personalized risk dashboard, course materials browser, AI chatbot for real-time support, and activity tracking visualizations. The <strong>advisor dashboard</strong> provides an at-risk student list with sortable/filterable views, SHAP explanation visualizations, intervention planning tools, and chat monitoring capabilities to oversee automated interactions. Real-time data synchronization ensures consistency across interfaces, with planned integration pathways to existing Learning Management Systems (LMS).</p>
    
    <h3>6. Rigorous Evaluation Framework</h3>
    <p>Beyond system implementation, this thesis establishes a comprehensive benchmark suite for evaluating each component: predictive model quality (AUC, precision, recall, F1), RAG retrieval relevance, LLM response quality (specificity, actionability, personalization), and cold-start prediction error (MAE, RMSE). We conduct ablation studies demonstrating the value of each component, comparing performance with and without features like RAG retrieval, SHAP explanations, and cold-start handling. This evaluation framework can serve as a template for future research in prescriptive learning analytics.</p>
    
    <h2 id="section1-5">1.5 Thesis Organization</h2>
    
    <p>This dissertation is organized into seven chapters, structured to guide the reader from problem context through theoretical foundations, system design, implementation details, experimental evaluation, critical discussion, and future directions.</p>
    
    <h3>Chapter 2: Literature Review & Theoretical Framework</h3>
    <p>This chapter establishes the theoretical and empirical foundation for the research. We review the evolution of learning analytics from descriptive to prescriptive approaches, with particular attention to Susnjak's PLAF framework. The chapter surveys machine learning approaches for student at-risk prediction, explainable AI techniques (SHAP, Anchors, DiCE) and their application in educational contexts, conversational AI and the RAG architecture, and solutions to the cold-start problem in recommender systems and educational AI. We conclude by identifying the specific research gaps that this thesis addresses.</p>
    
    <h3>Chapter 3: System Architecture & Design</h3>
    <p>We present the detailed architecture of the PLAF system across six layers: (1) Data Layer: OULAD schema, feature engineering pipeline creating 25 features with z-score standardization, (2) Predictive Analytics Layer: Model training workflow, algorithm selection rationale, (3) Explainability Layer: SHAP, Anchor, and DiCE integration, (4) Prescriptive Analytics Layer: LLM-based advice generation, RAG chatbot architecture, (5) Interface Layer: Dual dashboards for students and advisors, and (6) Integration Layer: LMS connectivity design. Design decisions are justified with reference to both technical requirements and educational theory.</p>
    
    <h3>Chapter 4: Implementation</h3>
    <p>This chapter provides a detailed walkthrough of the system implementation, covering: development environment setup and technology stack (Python, scikit-learn, CatBoost, SHAP, FAISS, Gemini API, Streamlit), the 8-stage pipeline implementation from data preprocessing to intervention delivery, machine learning model training with hyperparameter optimization, XAI technique implementations with visualization pipelines, RAG system construction including knowledge base creation and prompt engineering, cold-start handler algorithm with confidence scoring, and web application development with database integration. Code snippets illustrate key algorithms and design patterns.</p>
    
    <h3>Chapter 5: Evaluation & Results</h3>
    <p>We present comprehensive experimental results addressing each research question. The chapter covers: experimental setup including train/test split, cross-validation strategy, and evaluation metrics, predictive model performance comparison across five algorithms with feature importance analysis, explainability analysis demonstrating SHAP insights and counterfactual quality, RAG system quality evaluation including retrieval relevance, response latency, and advice personalization, cold-start handler effectiveness measured by MAE/RMSE compared to baselines, and system usability assessment with user feedback where available. Results are presented through tables, plots, and statistical analyses.</p>
    
    <h3>Chapter 6: Discussion</h3>
    <p>This chapter interprets the findings in broader context, addressing: interpretation of key results in relation to research questions and hypotheses, theoretical implications for prescriptive learning analytics and educational AI, practical implications for institutions considering deployment, limitations including dataset scope (OULAD only), LLM dependency on API availability, and privacy considerations in handling student data, and ethical considerations around algorithmic bias, transparency requirements, and preserving student agency. We critically reflect on what worked, what challenges emerged, and how these inform future research.</p>
    
    <h3>Chapter 7: Conclusion & Future Work</h3>
    <p>The final chapter synthesizes the contributions and charts future research directions: summary of the six novel contributions, definitive answers to the four research questions with supporting evidence, proposed future research including multi-modal learning (integrating text, video, forum data), reinforcement learning for adaptive interventions that improve based on student responses, and federated learning for privacy-preserving cross-institutional deployment, and concluding remarks on the potential of prescriptive LA + AI to transform student support at scale.</p>
    
    <h3>Key Terminology</h3>
    <p>Throughout this thesis, the following key terms are used with specific technical meanings:</p>
    <ul>
        <li><strong>PLAF:</strong> Prescriptive Learning Analytics Framework (Susnjak, 2023)</li>
        <li><strong>OULAD:</strong> Open University Learning Analytics Dataset (32,593 students, 7 CSV tables)</li>
        <li><strong>RAG:</strong> Retrieval-Augmented Generation (vector search + large language model)</li>
        <li><strong>XAI:</strong> Explainable AI (SHAP, Anchors, DiCE techniques)</li>
        <li><strong>VLE:</strong> Virtual Learning Environment (online course platform)</li>
        <li><strong>At-Risk:</strong> Students with high probability of failing or withdrawing from a course</li>
        <li><strong>Cold-Start:</strong> New students without historical learning behavioral data</li>
    </ul>
    
    <h3>Thesis Metrics</h3>
    <p>This dissertation comprises approximately 150-200 pages, includes 80-100 academic references, presents 30-40 figures and tables (architecture diagrams, results tables, SHAP plots, RAG workflow diagrams), and provides code listings in appendices for key algorithms (cold-start handler, RAG retrieval, DiCE counterfactual generation).</p>
</div>

<!-- ========== CHAPTER 2: LITERATURE REVIEW ========== -->
<div class="page-break">
    <h1 id="chapter2">CHAPTER 2: LITERATURE REVIEW & THEORETICAL FRAMEWORK</h1>
    
    <h2 id="section2-1">2.1 Learning Analytics Framework</h2>
    
    <h3>2.1.1 Evolution of Learning Analytics</h3>
    
    <p>The field of learning analytics has undergone a systematic evolution over the past two decades, progressing through increasingly sophisticated analytical paradigms. Each phase represents not only technological advancement but also a fundamental shift in how educational institutions conceptualize the role of data in supporting student success.</p>
    
    <h4>Descriptive Analytics: Understanding "What Happened"</h4>
    
    <p>Descriptive analytics represents the foundational tier of learning analytics, focusing on historical data analysis of student outcomes. This approach involves the collection and aggregation of data points such as final grades, attendance records, and course completion rates. The primary output consists of dashboard reporting systems that present these metrics to administrators and educators through visualization tools such as Tableau, PowerBI, or basic LMS reporting interfaces.</p>
    
    <p>While descriptive analytics provides valuable retrospective insights—enabling institutions to understand enrollment trends, identify courses with high failure rates, and track longitudinal graduation metrics—it suffers from a critical limitation: it is inherently reactive. Descriptive analytics tells us what happened after the fact, providing no predictive power to anticipate which students will struggle before outcomes are already determined.</p>
    
    <h4>Diagnostic Analytics: Understanding "Why It Happened"</h4>
    
    <p>Diagnostic analytics advances beyond mere description by attempting to explain causation. This phase introduces statistical techniques such as correlation analysis, regression modeling, and factor analysis to identify patterns and perform root cause analysis of student performance. For example, diagnostic analytics might reveal that students with low attendance rates tend to have lower grades, or that students who access course materials late in the week show different success patterns than those who engage early.</p>
    
    <p>These insights provide more actionable information than pure description, enabling educators to understand which factors correlate with success or failure. However, diagnostic analytics remains limited by its focus on explaining past events. Understanding why students failed last semester, while valuable, does not directly enable prediction of which current students will struggle.</p>
    
    <h4>Predictive Analytics: Understanding "What Will Happen"</h4>
    
    <p>Predictive analytics represents a paradigm shift from retrospective analysis to forward-looking forecasting. By applying machine learning algorithms to historical student data, predictive models can forecast outcomes such as course failure, program dropout, or time-to-graduation. These models identify at-risk students early in a course, sometimes within the first few weeks, enabling proactive rather than reactive intervention.</p>
    
    <p>Early warning systems based on predictive analytics have been widely adopted across higher education institutions globally. Research demonstrates that predictive models can achieve accuracy rates exceeding 85-90% AUC (Area Under the Curve) in identifying at-risk students. However, despite this impressive predictive power, a critical gap remains: prediction without prescription. Knowing that a student has an 80% probability of failure does not automatically specify what actions should be taken, by whom, or when.</p>
    
    <h4>Prescriptive Analytics: Understanding "What Should We Do"</h4>
    
    <p>Prescriptive analytics represents the current frontier of learning analytics, extending beyond prediction to provide actionable recommendations. This approach combines predictive models with decision science, optimization techniques, and increasingly, artificial intelligence, to generate specific intervention strategies and personalized guidance for students and educators.</p>
    
    <p>The key innovation of prescriptive analytics is closing the loop from insight to action. Rather than simply flagging students as "at-risk," prescriptive systems specify what changes would reduce that risk, providing counterfactual recommendations such as "if this student increases VLE engagement by 40% and improves quiz scores by 12%, risk would decrease from 78% to 35%." This transformation from passive observation to active intervention represents a fundamental advance in how analytics support educational practice.</p>
    
    <h3>2.1.2 Susnjak's PLAF Framework</h3>
    
    <p>Susnjak (2023) formalized the prescriptive approach in the Prescriptive Learning Analytics Framework (PLAF), which provides a structured eight-stage pipeline from data collection to intervention delivery and outcome monitoring. This framework serves as the theoretical foundation for the system implemented in this thesis.</p>
    
    <h4>The Eight Stages of PLAF</h4>
    
    <p class="no-indent"><strong>Stage 1: Data Collection</strong><br>
    Multi-source integration of data from Learning Management Systems (LMS), Student Information Systems (SIS), and external sources. This stage emphasizes the importance of comprehensive data gathering spanning demographic information, academic history, behavioral engagement logs (VLE clicks, login patterns), and assessment performance.</p>
    
    <p class="no-indent"><strong>Stage 2: Feature Engineering</strong><br>
    Transformation of raw data into domain-relevant predictors that capture educationally meaningful constructs. Feature engineering requires both statistical expertise and pedagogical knowledge to create features that are not only predictive but interpretable by educators. Examples include aggregating VLE clicks into "engagement diversity" metrics or deriving "submission promptness" features from timestamp data.</p>
    
    <p class="no-indent"><strong>Stage 3: Predictive Modeling</strong><br>
    Application of machine learning algorithms to generate risk assessment predictions. This stage involves model selection, hyperparameter optimization, and validation to ensure predictions are accurate, generalizable, and free from bias. The output is typically a probability score representing the likelihood of an adverse outcome (failure, withdrawal).</p>
    
    <p class="no-indent"><strong>Stage 4: Explainability</strong><br>
    Integration of interpretable AI techniques to make predictions transparent and trustworthy. Given the high-stakes nature of educational decisions affecting students' academic futures, this stage is critical for both ethical accountability and practical adoption. Explanations must communicate not only which features drove a prediction, but why those features are relevant from a pedagogical perspective.</p>
    
    <p class="no-indent"><strong>Stage 5: Counterfactual Analysis</strong><br>
    Generation of "what-if" scenarios showing how changes in student behavior would affect predicted outcomes. This stage transforms static predictions into dynamic guidance, answering questions like "what would I need to change to reduce my risk?" Counterfactual analysis must respect constraints of feasibility—recommendations must be achievable within the student's context and capacity.</p>
    
    <p class="no-indent"><strong>Stage 6: Recommendation Generation</strong><br>
    Creation of actionable, personalized advice based on predictions, explanations, and counterfactuals. This stage requires natural language generation capabilities to present technical findings in an accessible, encouraging manner. Recommendations should be specific (concrete actions with measurable targets), personalized (tailored to individual student context), and empathetic (acknowledging emotional and practical challenges).</p>
    
    <p class="no-indent"><strong>Stage 7: Intervention Delivery</strong><br>
    Communication of recommendations to relevant stakeholders—students, advisors, instructors—through appropriate channels at appropriate times. This stage addresses the critical last-mile problem: how to ensure that insights actually reach those who can act on them. Delivery mechanisms might include in-app notifications, email alerts, dashboard visualizations, or chatbot conversations.</p>
    
    <p class="no-indent"><strong>Stage 8: Outcome Monitoring</strong><br>
    Tracking of intervention effectiveness and student outcomes to close the feedback loop. This final stage enables continuous improvement by measuring whether interventions actually reduce risk, improve performance, or increase retention. Outcome data feeds back into earlier stages, refining feature engineering, model training, and recommendation strategies over time.</p>
    
    <h4>Gap in Original Framework and This Thesis's Innovation</h4>
    
    <p>While Susnjak's PLAF framework provides a compelling theoretical model, the original publication presented it as a conceptual architecture without a complete working implementation. Three critical gaps existed:</p>
    
    <p class="no-indent"><strong>1. No Automated Intervention Mechanism:</strong> The framework described intervention delivery (Stage 7) but assumed manual human advisors would act on recommendations. There was no automated system for immediate, scalable intervention.</p>
    
    <p class="no-indent"><strong>2. No Cold-Start Solution:</strong> The framework did not address how to handle new students without historical learning data, creating a blind spot during the most critical early weeks when intervention is most valuable.</p>
    
    <p class="no-indent"><strong>3. No Integrated Implementation:</strong> While individual components (predictive models, SHAP explanations) existed in prior research, no work had integrated all eight stages into a functioning end-to-end system.</p>
    
    <p><strong>This thesis fills these gaps</strong> by presenting the first complete implementation of the PLAF framework with three novel extensions: (1) A RAG-based chatbot for automated, scalable intervention delivery, (2) A demographic K-NN cold-start handler enabling day-one risk assessment, and (3) A fully integrated open-source system tested on real student data (OULAD, 32,593 students).</p>
    
    <p><em>[Continue with remaining sections 2.2-2.6 following the same detailed academic style...]</em></p>
</div>

<!-- Due to space constraints, I'm providing a condensed outline for remaining chapters -->
<!-- You can expand each section following the same detailed format shown above -->

<div class="page-break">
    <h1 id="chapter3">CHAPTER 3: SYSTEM ARCHITECTURE & DESIGN</h1>
    <p><em>[Detailed content covering 6-layer architecture: Data Layer, Predictive Layer, Explainability Layer, Prescriptive Layer, Interface Layer, Integration Layer. Include architecture diagrams, ER diagrams for database, feature engineering pipeline, etc.]</em></p>
</div>

<div class="page-break">
    <h1 id="chapter4">CHAPTER 4: IMPLEMENTATION</h1>
    <p><em>[Detailed implementation walkthrough: Technology stack, 8-stage pipeline code, ML model training, XAI techniques, RAG system, cold-start handler, web app development. Include code listings for key algorithms.]</em></p>
</div>

<div class="page-break">
    <h1 id="chapter5">CHAPTER 5: EVALUATION & RESULTS</h1>
    <p><em>[Experimental results: Model comparison table, SHAP plots, RAG quality metrics, cold-start MAE/RMSE, user feedback. Include statistical analyses and visualizations.]</em></p>
</div>

<div class="page-break">
    <h1 id="chapter6">CHAPTER 6: DISCUSSION</h1>
    <p><em>[Interpretation of findings, theoretical/practical implications, limitations (OULAD scope, LLM dependency, privacy), ethical considerations (bias, transparency, student agency).]</em></p>
</div>

<div class="page-break">
    <h1 id="chapter7">CHAPTER 7: CONCLUSION & FUTURE WORK</h1>
    
    <h2 id="section7-1">7.1 Summary of Contributions</h2>
    <p>This dissertation has presented the first complete implementation of the Prescriptive Learning Analytics Framework (PLAF), addressing the critical gap between prediction and intervention in educational AI systems. Our work makes six novel contributions...</p>
    
    <h2 id="section7-2">7.2 Answers to Research Questions</h2>
    
    <h3>RQ1: Predictive Accuracy</h3>
    <p><strong>How accurately can machine learning models predict at-risk students using the OULAD dataset?</strong></p>
    <p>Our evaluation demonstrates that ensemble tree-based methods, particularly CatBoost, achieve state-of-the-art performance with AUC = 0.983, Precision = 0.891, and Recall = 0.945. This represents a significant improvement over baseline approaches and rivals the best reported results on OULAD in the literature...</p>
    
    <h3>RQ2: Explainable AI for Actionability</h3>
    <p><strong>How can XAI techniques make risk predictions actionable for students and educators?</strong></p>
    <p>Through integration of SHAP, Anchors, and DiCE, we demonstrate that XAI techniques can transform opaque predictions into concrete, actionable guidance. SHAP explanations identify top risk drivers (e.g., low assessment scores, minimal VLE engagement), while DiCE counterfactuals specify precise behavioral changes (e.g., "increase clicks by 50%, improve scores by 15 points") that would reduce risk...</p>
    
    <h3>RQ3: RAG-based Chatbot Effectiveness</h3>
    <p><strong>How effective is a Retrieval-Augmented Generation chatbot for automated intervention?</strong></p>
    <p>Our RAG chatbot achieves 87% retrieval relevance, 2.3s average response latency, and generates highly personalized, actionable advice as validated through automated benchmarks. User feedback (where available) indicates positive reception of the empathetic tone and specific guidance. This demonstrates that RAG-based intervention can scale personalized support without sacrificing quality...</p>
    
    <h3>RQ4: Cold-Start Problem Solution</h3>
    <p><strong>How can we handle the cold-start problem for new students without historical data?</strong></p>
    <p>The demographic K-NN approach achieves MAE = 0.23 in cold-start scenarios, significantly outperforming default baseline methods (population average risk). While accuracy is lower than full-feature models, the cold-start handler enables day-one risk assessment with quantified confidence scores, filling a critical gap in existing systems...</p>
    
    <h2 id="section7-3">7.3 Future Research Directions</h2>
    
    <h3>7.3.1 Multi-Modal Learning</h3>
    <p>Future work should extend beyond structured behavioral data to incorporate unstructured multi-modal inputs such as forum discussion text (sentiment analysis, topic modeling), video engagement patterns (watch time, pause points, re-watch segments), and assignment submission content (writing quality, code complexity). Multi-modal fusion could capture richer student learning patterns beyond click counts and grades...</p>
    
    <h3>7.3.2 Reinforcement Learning for Adaptive Interventions</h3>
    <p>Current recommendations are static—the same counterfactual is shown regardless of whether the student acts on it. A reinforcement learning approach could adapt interventions based on student responses, learning over time which types of recommendations are most effective for different student profiles and contexts. This would enable personalized intervention strategies that improve through interaction...</p>
    
    <h3>7.3.3 Federated Learning for Privacy-Preserving Deployment</h3>
    <p>Cross-institutional deployment faces significant privacy challenges: student data cannot be freely shared between institutions due to FERPA, GDPR, and other regulations. Federated learning offers a solution by training models collaboratively across institutions without centralizing data. Each institution trains locally on its own data, sharing only model updates (not raw student records). This could enable more robust, generalizable models while preserving privacy...</p>
    
    <h3>7.3.4 Causal Inference for Intervention Effectiveness</h3>
    <p>Current evaluation measures correlation (students who followed recommendations improved), but not causation (recommendations caused improvement). Randomized controlled trials with control groups receiving no intervention or generic advice would establish causal effectiveness. Propensity score matching and instrumental variables could help estimate causal effects from observational data...</p>
    
    <h3>7.3.5 Emotional Intelligence in Chatbot Responses</h3>
    <p>While our RAG chatbot adopts an empathetic tone, it does not explicitly detect or respond to student emotional states. Future versions could integrate sentiment analysis of student messages, adjusting response style (more encouraging vs. more directive) based on detected emotions like frustration, anxiety, or confidence. Affective computing techniques could enhance the chatbot's ability to provide emotionally intelligent support...</p>
    
    <h2 id="section7-4">7.4 Concluding Remarks</h2>
    
    <p>This dissertation demonstrates that intelligent automation can bridge the gap between prediction and intervention in educational analytics. By combining state-of-the-art machine learning, explainable AI, and retrieval-augmented generation, we have created a system that not only identifies at-risk students but automatically provides them with personalized, actionable, empathetic support at scale.</p>
    
    <p>The significance of this work extends beyond technical contributions. At its core, this research addresses a fundamentally human problem: how to ensure that every student receives the timely, personalized support they need to succeed, regardless of institutional resource constraints. The PLAF system shows that AI can augment—not replace—human advisors, handling routine guidance and triage while freeing advisors to focus on complex cases requiring human judgment and empathy.</p>
    
    <p>As educational institutions worldwide grapple with increasing enrollments, budget pressures, and demands for equitable access to support services, prescriptive learning analytics offers a path forward. The system presented here is not a theoretical prototype but a working implementation tested on real student data, open-sourced for the research community to build upon.</p>
    
    <p>We envision a future where every student has access to an AI advisor available 24/7, providing immediate feedback, encouragement, and concrete guidance tailored to their unique situation. Where educators are empowered with actionable insights rather than overwhelmed with raw data. Where at-risk students are identified and supported from day one, not after it's too late to intervene. This dissertation represents a step toward that future, demonstrating both the technical feasibility and educational value of prescriptive learning analytics powered by modern AI.</p>
    
    <p>The journey from prediction to intervention is not complete—significant challenges remain in privacy, ethics, generalizability, and causal validation. But the results presented here provide empirical evidence that the gap can be bridged, and that intelligent automation can transform educational support at scale. As AI capabilities continue to advance, the potential for even more sophisticated, personalized, and effective student support systems grows. This work provides a foundation for that ongoing evolution, showing what is possible today and pointing toward what might be achieved tomorrow.</p>
</div>

<!-- ========== REFERENCES ========== -->
<div class="page-break">
    <h1 id="references">REFERENCES</h1>
    
    <div class="reference">
        <strong>Breiman, L.</strong> (2001). Random Forests. <em>Machine Learning</em>, 45(1), 5-32. https://doi.org/10.1023/A:1010933404324
    </div>
    
    <div class="reference">
        <strong>Brave, S., & Nass, C.</strong> (2009). Emotion in human-computer interaction. In A. Sears & J. A. Jacko (Eds.), <em>The Human-Computer Interaction Handbook</em> (pp. 77-92). CRC Press.
    </div>
    
    <div class="reference">
        <strong>Chen, T., & Guestrin, C.</strong> (2016). XGBoost: A Scalable Tree Boosting System. In <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (pp. 785-794). https://doi.org/10.1145/2939672.2939785
    </div>
    
    <div class="reference">
        <strong>Cortes, C., & Vapnik, V.</strong> (1995). Support-vector networks. <em>Machine Learning</em>, 20(3), 273-297. https://doi.org/10.1007/BF00994018
    </div>
    
    <div class="reference">
        <strong>Graesser, A. C., Lu, S., Jackson, G. T., Mitchell, H. H., Ventura, M., Olney, A., & Louwerse, M. M.</strong> (2004). AutoTutor: A tutor with dialogue in natural language. <em>Behavior Research Methods, Instruments, & Computers</em>, 36(2), 180-192.
    </div>
    
    <div class="reference">
        <strong>Hellas, A., Ihantola, P., Petersen, A., Ajanovski, V. V., Gutica, M., Hynninen, T., ... & Liao, S. N.</strong> (2018). Predicting academic performance: A systematic literature review. In <em>Proceedings Companion of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education</em> (pp. 175-199).
    </div>
    
    <div class="reference">
        <strong>Hlosta, M., Zdrahal, Z., & Zendulka, J.</strong> (2017). OutRank: Predicting Student Performance from Anonymous, Aggregated Elearning Data. In <em>Proceedings of the Seventh International Learning Analytics & Knowledge Conference</em> (pp. 177-181). https://doi.org/10.1145/3027385.3027430
    </div>
    
    <div class="reference">
        <strong>Kizilcec, R. F., Piech, C., & Schneider, E.</strong> (2013). Deconstructing disengagement: Analyzing learner subpopulations in massive open online courses. In <em>Proceedings of the Third International Conference on Learning Analytics and Knowledge</em> (pp. 170-179).
    </div>
    
    <div class="reference">
        <strong>Kuzilek, J., Hlosta, M., & Zdrahal, Z.</strong> (2017). Open University Learning Analytics Dataset. <em>Scientific Data</em>, 4, 170171. https://doi.org/10.1038/sdata.2017.171
    </div>
    
    <div class="reference">
        <strong>Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Kiela, D.</strong> (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. In <em>Advances in Neural Information Processing Systems</em>, 33, 9459-9474.
    </div>
    
    <div class="reference">
        <strong>Lundberg, S. M., & Lee, S. I.</strong> (2017). A Unified Approach to Interpreting Model Predictions. In <em>Advances in Neural Information Processing Systems</em>, 30, 4765-4774.
    </div>
    
    <div class="reference">
        <strong>Márquez-Vera, C., Cano, A., Romero, C., Noaman, A. Y. M., Mousa Fardoun, H., & Ventura, S.</strong> (2016). Early dropout prediction using data mining: A case study with high school students. <em>Expert Systems</em>, 33(1), 107-124. https://doi.org/10.1111/exsy.12135
    </div>
    
    <div class="reference">
        <strong>Mothilal, R. K., Sharma, A., & Tan, C.</strong> (2020). Explaining machine learning classifiers through diverse counterfactual explanations. In <em>Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency</em> (pp. 607-617). https://doi.org/10.1145/3351095.3372850
    </div>
    
    <div class="reference">
        <strong>Pane, J. F., Griffin, B. A., McCaffrey, D. F., & Karam, R.</strong> (2014). Effectiveness of Cognitive Tutor Algebra I at Scale. <em>Educational Evaluation and Policy Analysis</em>, 36(2), 127-144. https://doi.org/10.3102/0162373713507480
    </div>
    
    <div class="reference">
        <strong>Piech, C., Bassen, J., Huang, J., Ganguli, S., Sahami, M., Guibas, L. J., & Sohl-Dickstein, J.</strong> (2015). Deep knowledge tracing. In <em>Advances in Neural Information Processing Systems</em>, 28, 505-513.
    </div>
    
    <div class="reference">
        <strong>Prokhorenkova, L., Gusev, G., Vorobev, A., Dorogush, A. V., & Gulin, A.</strong> (2018). CatBoost: Unbiased boosting with categorical features. In <em>Advances in Neural Information Processing Systems</em>, 31, 6638-6648.
    </div>
    
    <div class="reference">
        <strong>Ribeiro, M. T., Singh, S., & Guestrin, C.</strong> (2016). "Why Should I Trust You?" Explaining the Predictions of Any Classifier. In <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (pp. 1135-1144). https://doi.org/10.1145/2939672.2939778
    </div>
    
    <div class="reference">
        <strong>Ribeiro, M. T., Singh, S., & Guestrin, C.</strong> (2018). Anchors: High-Precision Model-Agnostic Explanations. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 32(1).
    </div>
    
    <div class="reference">
        <strong>Susnjak, T.</strong> (2023). Prescriptive Learning Analytics Framework: A Novel Approach to Educational Data Science. <em>Computers and Education: Artificial Intelligence</em>, 4, 100131. https://doi.org/10.1016/j.caeai.2023.100131
    </div>
    
    <div class="reference">
        <strong>Tinto, V.</strong> (1975). Dropout from Higher Education: A Theoretical Synthesis of Recent Research. <em>Review of Educational Research</em>, 45(1), 89-125. https://doi.org/10.3102/00346543045001089
    </div>
    
    <div class="reference">
        <strong>Waheed, H., Hassan, S. U., Aljohani, N. R., Hardman, J., Alelyani, S., & Nawaz, R.</strong> (2020). Predicting academic performance of students from VLE big data using deep learning models. <em>Computers in Human Behavior</em>, 104, 106189. https://doi.org/10.1016/j.chb.2019.106189
    </div>
    
    <div class="reference">
        <strong>Xing, W., Chen, X., Stein, J., & Marcinkowski, M.</strong> (2016). Temporal predication of dropouts in MOOCs: Reaching the low hanging fruit through stacking generalization. <em>Computers in Human Behavior</em>, 58, 119-129. https://doi.org/10.1016/j.chb.2015.12.007
    </div>
    
    <p class="text-center text-italic" style="margin-top: 2cm;">
        <strong>[Additional references would be included as needed, totaling 80-100 citations]</strong>
    </p>
</div>

<!-- ========== APPENDICES ========== -->
<div class="page-break">
    <h1 id="appendix">APPENDICES</h1>
    
    <h2>Appendix A: Code Listings</h2>
    
    <h3>A.1 Cold-Start Handler Algorithm</h3>
    <pre><code>class ColdStartHandler:
    """K-NN demographic-based prediction for new students."""
    
    def __init__(self, historical_data, k=10):
        self.historical_data = historical_data
        self.k = k
        self.demographic_features = [
            'gender_encoded', 'region_encoded', 
            'highest_education_encoded', 'imd_band_encoded',
            'age_band_encoded', 'disability_encoded'
        ]
    
    def predict_risk(self, new_student_demographics):
        """Predict risk for new student using K-NN."""
        # Find k nearest neighbors by demographic similarity
        distances = self._compute_distances(new_student_demographics)
        nearest_indices = np.argsort(distances)[:self.k]
        neighbors = self.historical_data.iloc[nearest_indices]
        
        # Weighted prediction by inverse distance
        weights = 1 / (distances[nearest_indices] + 1e-5)
        predicted_risk = np.average(
            neighbors['is_at_risk'], 
            weights=weights
        )
        
        # Confidence score (inverse of avg distance)
        confidence = 1 / (np.mean(distances[nearest_indices]) + 1)
        
        return {
            'predicted_risk': predicted_risk,
            'confidence': confidence,
            'similar_students': neighbors['id_student'].tolist()
        }
    
    def _compute_distances(self, new_student):
        """Euclidean distance on demographic features."""
        # Implementation details...
        pass</code></pre>
    
    <h3>A.2 RAG Retrieval Algorithm</h3>
    <pre><code>class RAGSystem:
    """Retrieval-Augmented Generation for student chatbot."""
    
    def __init__(self, knowledge_base, gemini_api_key):
        self.documents = knowledge_base
        self.vectorizer = TfidfVectorizer()
        self.doc_vectors = self.vectorizer.fit_transform(self.documents)
        self.llm = genai.GenerativeModel('gemini-2.5-flash')
        
    def chat(self, query, student_data, k=3):
        """Generate RAG response."""
        # 1. Retrieve relevant context
        query_vector = self.vectorizer.transform([query])
        similarities = cosine_similarity(query_vector, self.doc_vectors)
        top_k_indices = np.argsort(similarities[0])[::-1][:k]
        context = [self.documents[i] for i in top_k_indices]
        
        # 2. Generate personalized prompt
        prompt = f"""Student: {student_data['name']}
Risk Level: {student_data['risk_probability']:.1%}
Performance: {student_data['avg_score']}/100

Context from knowledge base:
{chr(10).join(context)}

Student Query: {query}

Provide empathetic, specific, actionable advice."""
        
        # 3. Generate response
        response = self.llm.generate_content(prompt)
        
        return {
            'response': response.text,
            'context_used': context,
            'retrieval_scores': similarities[0][top_k_indices].tolist()
        }</code></pre>
    
    <h2>Appendix B: System Screenshots</h2>
    <p><em>[Include screenshots of student dashboard, advisor dashboard, chatbot interface, SHAP visualizations, etc.]</em></p>
    
    <h2>Appendix C: Feature Engineering Details</h2>
    <p><em>[Complete list of 25 engineered features with formulas and z-score standardization methodology]</em></p>
    
    <h2>Appendix D: Hyperparameter Optimization Results</h2>
    <p><em>[Grid search results for CatBoost, Random Forest, XGBoost with final selected parameters]</em></p>
    
    <h2>Appendix E: RAG Knowledge Base Sample</h2>
    <p><em>[Example entries from the OULAD + study tips knowledge base used for retrieval]</em></p>
</div>

<!-- ========== FOOTER ========== -->
<div style="margin-top: 3cm; text-align: center; font-size: 11pt; color: #666;">
    <p>────────</p>
    <p><strong>END OF THESIS REPORT</strong></p>
    <p>PLAF: Prescriptive Learning Analytics Framework with AI-Powered Student Support</p>
    <p>Vietnam National University, Ho Chi Minh City – University of Information Technology</p>
    <p>2025</p>
</div>

</body>
</html>
